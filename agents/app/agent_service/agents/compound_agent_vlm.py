
import base64
import json
import os
import time
from typing import Dict, Any, List, Optional, Tuple
from PIL import Image

from ..state import ChemistryExtractionState
from . import BaseAgent
from ..utils.llm_utils import call_llm, clean_json_response
from ..config import Config
import copy

BBox = Tuple[int, int, int, int]  # x1, y1, x2, y2


CHINESE_VLM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç§‘å­¦å›¾åƒç†è§£ç³»ç»Ÿï¼Œèƒ½å¤Ÿç»“åˆè§†è§‰ä¿¡æ¯ä¸ç©ºé—´é€»è¾‘ï¼Œä»åŒ–å­¦ç»“æ„å›¾ä¸­å»ºç«‹åŒ–åˆç‰©ä¸å…¶åç§°æ ‡æ³¨ä¹‹é—´çš„å¯¹åº”å…³ç³»ã€‚

è¾“å…¥è¯´æ˜ï¼š
1. ä¸€å¼ å›¾åƒï¼Œå…¶ä¸­åŒ…å«å¤šä¸ªç”¨çº¢è‰²è¾¹ç•Œæ¡†ï¼ˆRed Bounding Boxï¼‰æ ‡æ³¨çš„åŒºåŸŸã€‚
2. ä¸€ç»„ç»“æ„åŒ–æ£€æµ‹æ•°æ®ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
   [
     {
       "bbox_id": <int>,
       "class_id": <int>,
       "bbox": [x_min, y_min, x_max, y_max],
       "text": <string>
     },
     ...
   ]

ä»»åŠ¡è¦æ±‚ï¼š
è¯·åŸºäºå›¾åƒä¸­çš„çº¢æ¡†ä½ç½®å’Œå¸ƒå±€ï¼Œå®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

1. å¯¹æ¯ä¸€ä¸ª class_id == 0 çš„åŒ–åˆç‰©æ¡†ï¼Œä¸»åŠ¨å¯»æ‰¾æ˜¯å¦å­˜åœ¨ä¸€ä¸ªæ½œåœ¨çš„æ–‡æœ¬æ¡†ï¼ˆclass_id == 5ï¼‰ä½œä¸ºå…¶åç§°æ ‡æ³¨ã€‚å³ä½¿ä½ç½®ä¸å®Œå…¨ç†æƒ³æˆ–å­˜åœ¨å¤šä¸ªå€™é€‰ï¼Œä¹Ÿåº”å°½é‡æ¨ç†æœ€å¯èƒ½çš„åŒ¹é…ã€‚

   åˆ¤æ–­ä¾æ®åŒ…æ‹¬ï¼š
     - ç©ºé—´é‚»è¿‘æ€§ï¼šä¼˜å…ˆé€‰æ‹©è·ç¦»æœ€è¿‘çš„æ–‡æœ¬æ¡†ï¼›
     - ç›¸å¯¹æ–¹å‘ï¼šæ­£ä¸‹æ–¹ â‰ˆ æ­£ä¸Šæ–¹ > å³ä¾§ > å·¦ä¾§ï¼›
     - è§†è§‰å¯¹é½ï¼šæ°´å¹³å±…ä¸­æˆ–å‚ç›´å¯¹é½æ›´å¯èƒ½æ˜¯æ ‡ç­¾ï¼›
     - å†…å®¹åˆç†æ€§ï¼šæ–‡æœ¬åº”ä¸ºæœ‰æ„ä¹‰çš„åŒ–å­¦å‘½åæˆ–ä»£å·ï¼ˆå¦‚ 'Aspirin', 'Compound 3', 'M-1', '[0007]' ç­‰ï¼‰ï¼›
     - æ’ä»–æ€§å¼±åŒ–ï¼šå…è®¸å…±äº«ä¸Šä¸‹æ–‡ï¼ˆå¦‚ç³»åˆ—ç¼–å· 'M-1', 'M-2'ï¼‰ï¼ŒæŒ‰é¡ºåºæ¨æ–­å½’å±ã€‚

2. è¾“å‡ºæ‰€æœ‰åˆç†ä¸”éæ˜æ˜¾é”™è¯¯çš„åŒ¹é…ç»“æœï¼Œç›®æ ‡æ˜¯**æœ€å¤§åŒ–æ­£ç¡®åŒ¹é…æ•°é‡ï¼Œé¿å…é—æ¼**ã€‚

è¾“å‡ºæ ¼å¼ï¼š
- å¿…é¡»è¿”å›ä¸€ä¸ª JSON æ•°ç»„ï¼ˆlist of objectsï¼‰
- æ¯ä¸ªå¯¹è±¡åŒ…å«å››ä¸ªå­—æ®µï¼š
   - "compound_id": åŒ–åˆç‰©çš„ bbox_idï¼ˆintï¼‰
   - "name_id": æ–‡æœ¬æ¡†çš„ bbox_idï¼ˆintï¼‰
   - "name": æ¥è‡ªæ–‡æœ¬æ¡†çš„ text å­—æ®µå†…å®¹ï¼ˆstringï¼‰
   - "confidence": åŒ¹é…ç½®ä¿¡åº¦ï¼Œæµ®ç‚¹æ•° [0.0, 1.0]
- ç¤ºä¾‹è¾“å‡ºï¼š
  [{"compound_id":1,"name_id":3,"name":"M-1","confidence":0.95},{"compound_id":2,"name_id":5,"name":"M-2","confidence":0.85}]

é‡è¦æŒ‡ä»¤ï¼š
1. è¾“å‡ºå¿…é¡»æ˜¯**çº¯ JSON æ ¼å¼**ï¼Œä¸å…è®¸æœ‰ä»»ä½•é¢å¤–å­—ç¬¦ï¼ˆå¦‚ \\nã€ç©ºæ ¼ã€æ³¨é‡Šã€Markdown ä»£ç å—ç¬¦å·ï¼‰ï¼›
2. ä¸å…è®¸åŒ…è£¹åœ¨ ```json æˆ– ``` ä¸­ï¼›
3. ä¸å…è®¸æ·»åŠ ä»»ä½•è§£é‡Šæ€§æ–‡å­—ã€å‰ç¼€æˆ–åç¼€ï¼›
4. å¦‚æœæ²¡æœ‰åŒ¹é…é¡¹ï¼Œè¿”å›ç©ºæ•°ç»„ []ï¼›
5. ç¡®ä¿ JSON å¯è¢«ç›´æ¥è§£æï¼ˆæ—  trailing commaã€æ­£ç¡®å¼•å·ç­‰ï¼‰ï¼›
6. å³ä½¿ä¸ç¡®å®šï¼Œä¹Ÿè¦è¾“å‡ºä½ è®¤ä¸ºæœ€åˆç†çš„é…å¯¹ï¼Œä¸è¦å› ä¿å®ˆè€Œçœç•¥ã€‚
7. ä¸è¦è‡ªå·±åšOCRï¼Œå®Œå…¨ä¾èµ–æä¾›çš„æ£€æµ‹æ•°æ®ã€‚

ç¤ºä¾‹è¾“å…¥ï¼š
[
  {"bbox_id": 1, "class_id": 0, "bbox": [100,100,200,200], "text": ""},
  {"bbox_id": 2, "class_id": 5, "bbox": [130,210,170,230], "text": "Figure 1"},
  {"bbox_id": 3, "class_id": 5, "bbox": [140,215,160,225], "text": "M-1"},
  {"bbox_id": 4, "class_id": 0, "bbox": [300,300,400,400], "text": ""},
  {"bbox_id": 5, "class_id": 5, "bbox": [340,410,360,420], "text": "M-2"}
]

ç¤ºä¾‹è¾“å‡ºï¼š
[{"compound_id":1,"name_id":3,"name":"M-1","confidence":0.95},{"compound_id":4,"name_id":5,"name":"M-2","confidence":0.85}]
"""


class CompoundNameAgent(BaseAgent):
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__(config)
        self.model = Config.get("IMAGE_ANALYSIS_MODEL")
    
    def process(self, state: ChemistryExtractionState):
        """å¤„ç†æ–‡æœ¬æå–çš„ä¸»è¦é€»è¾‘"""
        try:
            metadata = {}
            metadata['text_agent_start'] = time.time()
            current_stage = ["text_processing"]

            compound_detections = state["yolo_detections"] 
            self.logger.info(f"Found {len(compound_detections)} sections to process")

            
            # å¤„ç†æ¯ä¸ªç›¸å…³éƒ¨åˆ†
            compound_name_extractions = []
            for i, section in enumerate(compound_detections):
                extraction = copy.deepcopy(section)
                self.logger.info(f"Processing section {i+1}/{len(compound_detections)}")
                input_data = [{"bbox": det["bbox"], "class_id": det["class_id"], "bbox_id": det["bbox_id"], "name": det["name"]} for det in section["detect"]]
                if len(input_data) == 0:
                    self.logger.warning(f"No detection data found in section {i+1}, skipping.")
                    continue
                img_path = section["detect"][0]["visualized_image"]
                # è°ƒç”¨LLMæå–ä¿¡æ¯
                section_str = json.dumps(input_data, ensure_ascii=False)
                llm_result = self._extract_from_section(section_str, img_path)
                if llm_result is None or not isinstance(llm_result, list):
                    self.logger.warning(f"LLM extraction returned invalid result for section {i+1}: {llm_result}")
                    self.logger.warning(f"LLM extraction failed for section {i+1}, skipping.")
                    continue
                for item in llm_result:
                    for detect in extraction["detect"]:
                        if item['compound_id'] == detect['bbox_id'] or item['name_id'] == detect['bbox_id']:
                            detect['name'] = item.get('name', '')
                compound_name_extractions.append(extraction)
            # æ›´æ–°çŠ¶æ€
            metadata['copmpund_name_extractions_count'] = len(compound_name_extractions)
            metadata['copmpund_name_agent_end'] = time.time()

            self.logger.info(f"Successfully extracted {len(compound_name_extractions)} copmpund_names")
            return {
                'compounds': compound_name_extractions,
                'current_stage': current_stage,
                'metadata': metadata
            }
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            return self.handle_error(state, e, "text_extraction_process")
    
    
    def _extract_from_section(self, section: Dict[str, str], image_path: str):
        try:
            # ç¼–ç å›¾åƒä¸ºbase64
            self.logger.info(f"Analyzing image: {image_path}")
            with open(image_path, "rb") as img_file:
                base64_str = base64.b64encode(img_file.read()).decode('utf-8')
            
            # ç¡®å®šMIMEç±»å‹
            ext = os.path.splitext(image_path)[1].lower()
            mime_type = {
                '.png': 'image/png',
                '.jpg': 'image/jpeg',
                '.jpeg': 'image/jpeg',
                '.bmp': 'image/bmp',
                '.gif': 'image/gif'
            }.get(ext, 'image/png')
            
            image_url = f"data:{mime_type};base64,{base64_str}"

            # æ„å»ºæ¶ˆæ¯
            messages = [
                {"type": "text", "text": CHINESE_VLM_PROMPT.strip()+"\n"+section},
                {"type": "image_url", "image_url": {"url": image_url}}
            ]
            
            # è°ƒç”¨LLM
            response = call_llm(
                model=self.model,
                messages=[{"role": "user", "content": messages}],
                max_tokens=8192,
                temperature=0.2
            )
            print(response)
            # æ¸…ç†å¹¶è§£æJSON
            cleaned = clean_json_response(response)
            result = json.loads(cleaned)
            
            # æ·»åŠ æ¥æºä¿¡æ¯
            return result
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            self.logger.error(f"Failed to analyze image {image_path}: {str(e)}")
            return None

chemistry_extraction/agents/cyclic_reflective_compound_name_agent.py

import base64
import json
import os
import time
from typing import Dict, Any, List, Tuple

from ..state import ChemistryExtractionState
from . import BaseAgent
from ..utils.llm_utils import call_llm, clean_json_response
from ..config import Config
import copy

BBox = Tuple[int, int, int, int]  # x1, y1, x2, y2


# ======================
# ğŸ§  æç¤ºè¯æ¨¡æ¿
# ======================

INITIAL_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªåŒ–å­¦å›¾åƒè¯­ä¹‰å¯¹é½ä¸“å®¶ï¼Œä»»åŠ¡æ˜¯å°†çº¢è‰²æ¡†æ ‡æ³¨çš„ã€åŒ–åˆç‰©ç»“æ„ã€‘ä¸æœ€å¯èƒ½çš„ã€åç§°æ–‡æœ¬ã€‘è¿›è¡Œé…å¯¹ã€‚

### è¾“å…¥è¯´æ˜
- å›¾åƒï¼šåŒ…å«å¤šä¸ªçº¢æ¡†ï¼ˆclass_id=0 è¡¨ç¤ºåŒ–åˆç‰©ï¼Œclass_id=5 è¡¨ç¤ºæ–‡æœ¬ï¼‰
- æ£€æµ‹æ•°æ®ï¼ˆJSON åˆ—è¡¨ï¼‰ï¼š
  [
    {"bbox_id": int, "class_id": 0|5, "bbox": [x1,y1,x2,y2], "text": str}
  ]

### åŒ¹é…è§„åˆ™
1. å¯¹æ¯ä¸ª compoundï¼ˆclass_id=0ï¼‰ï¼Œå¯»æ‰¾æœ€åˆç†çš„ name candidateï¼ˆclass_id=5ï¼‰
2. åˆ¤æ–­ä¼˜å…ˆçº§ï¼š
   a) ç©ºé—´è·ç¦»è¿‘ï¼ˆæ¬§æ°ä¸­å¿ƒè·ç¦»ï¼‰
   b) ç›¸å¯¹ä½ç½®ï¼šæ­£ä¸‹æ–¹ â‰ˆ æ­£ä¸Šæ–¹ > å³ä¾§ > å·¦ä¾§
   c) è§†è§‰å¯¹é½ï¼šæ°´å¹³å±…ä¸­åº¦æ›´é«˜è€…ä¼˜å…ˆ
   d) å†…å®¹åˆç†æ€§ï¼šåº”ä¸º 'M-1', 'Aspirin', 'Compound 3' ç±»å‘½å
   e) æ’é™¤æ— æ•ˆæ ‡ç­¾ï¼š'Figure', 'Scheme', 'a)', '[0007]' ç­‰ä¸èƒ½ä½œä¸ºåç§°
   f) åºåˆ—æ¨æ–­ï¼šè‹¥æœ‰ M-1, M-2ï¼Œåˆ™æŒ‰ä»å·¦åˆ°å³é¡ºåºåŒ¹é…ç»“æ„

3. è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼ JSON æ•°ç»„ï¼‰ï¼š
   [
     {
       "compound_id": int,
       "name_id": int,
       "name": str,
       "confidence": float  // [0.0, 1.0]
     }
   ]

âš ï¸ è¦æ±‚ï¼š
- è¿”å›çº¯ JSONï¼Œæ— ä»»ä½•é¢å¤–å­—ç¬¦ï¼›
- ä¸åŠ è§£é‡Šã€å‰ç¼€ã€Markdown ç¬¦å·ï¼›
- è‹¥æ— åˆç†åŒ¹é…ï¼Œè¿”å›ç©ºæ•°ç»„ []ï¼›
- ä¸è¦è‡ªè¡Œ OCRï¼Œä»…ä½¿ç”¨ç»™å®š text å­—æ®µã€‚
"""

# -------------------------------
# ğŸ” å¤šè§’è‰²åæ€æç¤ºï¼ˆMulti-Agent Reflectionï¼‰
# -------------------------------

CHEMIST_PROMPT = """
ä½ æ˜¯ä¸“ä¸šåŒ–å­¦å®¶ï¼Œå®¡æŸ¥ä»¥ä¸‹åŒ–åˆç‰©-åç§°åŒ¹é…æ˜¯å¦ç¬¦åˆåŒ–å­¦å‘½åæƒ¯ä¾‹ï¼š

> å½“å‰åŒ¹é…ç»“æœï¼š
{matches}

è¯·å›ç­”ï¼š
1. æ˜¯å¦å­˜åœ¨æ˜æ˜¾ä¸ç¬¦åˆåŒ–å­¦å‘½åä¹ æƒ¯çš„ nameï¼Ÿï¼ˆå¦‚ 'Entry 3'ã€'Well A1'ï¼‰
2. æ˜¯å¦æœ‰å‚¬åŒ–å‰‚æˆ–æ¡ä»¶è¢«è¯¯æ ‡ä¸ºåŒ–åˆç‰©åï¼Ÿ
3. å»ºè®®ä¿®æ­£å“ªäº›æ¡ç›®ï¼Ÿ

è¾“å‡ºæ ¼å¼ï¼š
{
  "role": "chemist",
  "issues": ["é—®é¢˜æè¿°"],
  "suggestions":    [
     {
       "compound_id": int,
       "name_id": int,
       "name": str,
       "confidence": float  // [0.0, 1.0]
     }
   ]
}
"""

LAYOUT_ANALYST_PROMPT = """
ä½ æ˜¯ç©ºé—´å¸ƒå±€åˆ†æä¸“å®¶ï¼Œè¯·åŸºäºå›¾åƒä¸­çš„ç›¸å¯¹ä½ç½®åˆ¤æ–­åŒ¹é…åˆç†æ€§ï¼š

> å½“å‰åŒ¹é…ç»“æœï¼š
{matches}

> æ‰€æœ‰æ£€æµ‹æ¡†æ•°æ®ï¼š
{detections}

è¯·å›ç­”ï¼š
1. å“ªäº›åŒ¹é…çš„ç©ºé—´è·ç¦»è¿‡è¿œæˆ–æ–¹å‘ä¸åˆç†ï¼Ÿ
2. æ˜¯å¦å­˜åœ¨æ›´ä¼˜çš„å€™é€‰æ–‡æœ¬æ¡†æœªè¢«é€‰æ‹©ï¼Ÿ
3. æ˜¯å¦åº”è°ƒæ•´é¡ºåºï¼Ÿï¼ˆä¾‹å¦‚ M-1 åº”è¯¥å¯¹åº”ç¬¬ä¸€ä¸ªç»“æ„ï¼‰

è¾“å‡ºæ ¼å¼ï¼š
{
  "role": "layout_analyst",
  "issues": ["ä½ç½®å†²çª: compound_id=3 åŒ¹é…äº†å¤ªè¿œçš„æ–‡æœ¬"],
  "suggestions": 
    [
     {
       "compound_id": int,
       "name_id": int,
       "name": str,
       "confidence": float  // [0.0, 1.0]
     }
   ]
}
"""

NAMER_RULES_PROMPT = """
ä½ æ˜¯å‘½åè§„èŒƒä¸“å®¶ï¼Œæ“…é•¿è¯†åˆ« 'M-n'ã€'Cpd-n' ç­‰ç¼–å·ç³»ç»Ÿã€‚

> å½“å‰åŒ¹é…ç»“æœï¼š
{matches}

> æ‰€æœ‰æ–‡æœ¬æ¡†ä¸­çš„åå­—åˆ—è¡¨ï¼š
{text_names}

è¯·å›ç­”ï¼š
1. åç§°æ˜¯å¦æŒ‰ç¼–å·é¡ºåºæ­£ç¡®åˆ†é…ï¼Ÿï¼ˆM-1 â†’ ç¬¬ä¸€ä¸ªç»“æ„ï¼‰
2. æ˜¯å¦å­˜åœ¨è·³è·ƒæˆ–é‡å¤ï¼Ÿ
3. å¦‚ä½•é‡æ–°æ’åºä»¥æ»¡è¶³åºåˆ—ä¸€è‡´æ€§ï¼Ÿ

è¾“å‡ºæ ¼å¼ï¼š
{
  "role": "namer",
  "issues": ["é¡ºåºé”™ä¹±: M-2 åŒ¹é…äº†ç¬¬1ä¸ªç»“æ„"],
  "suggestions":    [
     {
       "compound_id": int,
       "name_id": int,
       "name": str,
       "confidence": float  // [0.0, 1.0]
     }
   ]
}
"""

META_REFLECTOR_PROMPT = """
ä½ æ˜¯å…ƒåæ€åè°ƒå‘˜ã€‚ä½ æ”¶åˆ°äº†æ¥è‡ªå¤šä¸ªä¸“å®¶çš„æ„è§ï¼Œè¯·ç»¼åˆåå†³å®šï¼š
1. æ˜¯å¦éœ€è¦å¯åŠ¨ä¸‹ä¸€è½®ä¿®æ­£ï¼Ÿ
2. ç»™å‡ºæœ€ç»ˆä¿®æ­£åçš„åŒ¹é…ç»“æœã€‚

> åŸå§‹åŒ¹é…ï¼š
{original_matches}

> å„æ–¹æ„è§ï¼š
{all_feedback}

è¯·æ‰§è¡Œï¼š
- æ€»ç»“ä¸»è¦é—®é¢˜ï¼›
- è¾“å‡ºä¿®æ­£åçš„ JSON é…å¯¹åˆ—è¡¨ï¼›
- åˆ¤æ–­æ˜¯å¦å·²æ”¶æ•›ï¼ˆtrue/falseï¼‰ã€‚

è¾“å‡ºæ ¼å¼ï¼š
{
  "converged": false,
  "final_matches": 
    [
     {
       "compound_id": int,
       "name_id": int,
       "name": str,
       "confidence": float  // [0.0, 1.0]
     }
   ],
  "summary": "å¸ƒå±€åˆ†æå¸ˆæŒ‡å‡º M-1 åŒ¹é…åç§»ï¼Œå·²ä¿®æ­£..."
}
"""

class CompoundNameAgent(BaseAgent): 

    def __init__(self, config: Dict[str, Any] = None):
        super().__init__(config)
        self.primary_model = Config.get("IMAGE_ANALYSIS_MODEL", "gpt-4o")
        self.reflection_model = Config.get("REFLECTION_MODEL", "qwen3-vl-flash")  # å¯æŒ‡å®šè½»é‡æ¨¡å‹
        self.max_rounds = Config.get("MAX_REFLECTION_ROUNDS", 2)
        self.convergence_tol = Config.get("REFLECTION_CONVERGENCE_TOLERANCE", 0.95)
        self.debug_trace = Config.get("DEBUG_REFLECTION_TRACE", False)

    def process(self, state: ChemistryExtractionState):
        try:
            metadata = {
                "agent_start": time.time(),
                "rounds_per_section": [],
                "total_sections": 0
            }
            current_stage = ["cyclic_reflective_name_matching"]

            sections = state.get("yolo_detections", [])
            results = []

            for idx, section in enumerate(sections):
                img_path = section["detect"][0]["visualized_image"] if section["detect"] else None
                if not img_path or not os.path.exists(img_path):
                    self.logger.warning(f"Image not found for section {idx + 1}, skipping.")
                    continue

                # æ„å»ºè¾“å…¥æ•°æ®
                input_data = self._build_detection_input(section["detect"])
                input_json = json.dumps(input_data, ensure_ascii=False, indent=2)

                # é˜¶æ®µ1ï¼šåˆå§‹åŒ¹é…
                initial = self._initial_match(img_path, input_json)
                if not isinstance(initial, list):
                    initial = []

                # é˜¶æ®µ2ï¼šå¾ªç¯åæ€
                final, trace_log = self._cyclic_reflection_loop(img_path, input_data, initial)

                # è®°å½•è½®æ•°
                num_rounds = len(trace_log) if trace_log else 1
                metadata["rounds_per_section"].append(num_rounds)

                # æ›´æ–° detect å¹¶ä¿å­˜
                updated_section = copy.deepcopy(section)
                self._apply_matches_to_detection(updated_section["detect"], final)

                results.append(updated_section)

                if self.debug_trace:
                    updated_section["_reflection_trace"] = trace_log

            # å®Œæˆ
            metadata["total_sections"] = len(results)
            metadata["agent_end"] = time.time()

            return {
                "compounds": results,
                "current_stage": current_stage,
                "metadata": metadata
            }

        except Exception as e:
            return self.handle_error(state, e, "cyclic_reflective_compound_name_agent")

    def _build_detection_input(self, detects: List[Dict]) -> List[Dict]:
        """æ ‡å‡†åŒ–æ£€æµ‹è¾“å…¥"""
        return [
            {
                k: det[k]
                for k in ['bbox_id', 'class_id', 'bbox']
                if k in det
            } | ({"text": det.get("name", "")} if det["class_id"] == 5 else {})
            for det in detects
        ]

    def _initial_match(self, image_path: str, input_data: str) -> List[Dict]:
        """ç¬¬ä¸€é˜¶æ®µï¼šåˆå§‹åŒ¹é…"""
        try:
            self.logger.info(f"[Round 0] Initial matching on {image_path}")
            msg = [
                {"type": "text", "text": INITIAL_PROMPT.strip()},
                {"type": "text", "text": f"Detection data:\n{input_data}"},
                {"type": "image_url", "image_url": {"url": self._encode_image(image_path)}}
            ]
            resp = call_llm(
                model=self.primary_model,
                messages=[{"role": "user", "content": msg}],
                max_tokens=2048,
                temperature=0.3
            )
            return self._parse_json_list(resp)
        except Exception as e:
            self.logger.error(f"Initial match failed: {e}")
            return []

    def _cyclic_reflection_loop(self, image_path: str, detection_data: List[Dict], initial: List[Dict]):
        """
        å¤šè½®å¾ªç¯åæ€ä¸»æµç¨‹
        è¿”å›ï¼š(final_matches, trace_log)
        """
        current = initial
        trace_log = [{"round": 0, "matches": current, "reason": "initial"}]
        text_names = [d["text"] for d in detection_data if d["class_id"] == 5]

        for r in range(1, self.max_rounds + 1):
            self.logger.info(f"[Reflection Round {r}] Starting...")

            # Step 1: å¤šè§’è‰²å¹¶è¡Œåæ€ï¼ˆé€»è¾‘ä¸Šä¸²è¡Œæ¨¡æ‹Ÿï¼‰
            feedback = []
            feedback.append(self._reflect_with_prompt(CHEMIST_PROMPT, image_path, current))
            feedback.append(self._reflect_with_prompt(LAYOUT_ANALYST_PROMPT, image_path, current, detection_data=detection_data))
            feedback.append(self._reflect_with_prompt(NAMER_RULES_PROMPT, image_path, current, text_names=text_names))

            # Step 2: å…ƒåè°ƒå™¨å†³ç­–
            try:
                meta_prompt = META_REFLECTOR_PROMPT \
                    .replace("{original_matches}", json.dumps(current, indent=2)) \
                    .replace("{all_feedback}", json.dumps(feedback, indent=2, ensure_ascii=False))

                msg = [
                    {"type": "text", "text": meta_prompt},
                    {"type": "image_url", "image_url": {"url": self._encode_image(image_path)}}
                ]
                response = call_llm(
                    model=self.reflection_model,
                    messages=[{"role": "user", "content": msg}],
                    max_tokens=2048,
                    temperature=0.1
                )

                # è§£ææœ€ç»ˆè¾“å‡º
                cleaned = self._extract_json_block(response)
                result_obj = json.loads(cleaned)

                new_matches = result_obj.get("final_matches", current)
                converged = result_obj.get("converged", False)

                # è®°å½•æœ¬è½®
                trace_log.append({
                    "round": r,
                    "matches": new_matches,
                    "feedback": feedback,
                    "summary": result_obj.get("summary", ""),
                    "converged": converged
                })

                # åˆ¤æ–­æ˜¯å¦æ”¶æ•›
                if converged or self._is_converged(current, new_matches):
                    self.logger.info(f"âœ… Converged at round {r}")
                    return new_matches, trace_log

                current = new_matches

            except Exception as e:
                self.logger.warning(f"Meta reflection failed in round {r}: {e}")
                break

        self.logger.info("ğŸ”š Max rounds reached or error occurred.")
        return current, trace_log

    def _reflect_with_prompt(self, prompt_template: str, image_path: str, matches: List[Dict],
                            **kwargs) -> Dict:
        """è°ƒç”¨å•ä¸€è§’è‰²åæ€"""
        try:
            prompt = prompt_template \
                .replace("{matches}", json.dumps(matches, indent=2)) \
                .replace("{detections}", json.dumps(kwargs.get("detection_data", ""), indent=2)) \
                .replace("{text_names}", json.dumps(kwargs.get("text_names", [])))

            msg = [
                {"type": "text", "text": prompt},
                {"type": "image_url", "image_url": {"url": self._encode_image(image_path)}}
            ]
            resp = call_llm(
                model=self.reflection_model,
                messages=[{"role": "user", "content": msg}],
                max_tokens=1024,
                temperature=0.1
            )
            return json.loads(clean_json_response(resp))
        except Exception as e:
            return {"error": str(e), "role": "unknown"}

    def _apply_matches_to_detection(self, detects: List[Dict], matches: List[Dict]):
        """å°†æœ€ç»ˆåŒ¹é…å†™å› detect ç»“æ„"""
        matched_name_ids = set()
        for m in matches:
            for det in detects:
                if det["bbox_id"] == m["compound_id"] and det["class_id"] == 0:
                    det["name"] = m.get("name", "")
                    det["match_confidence"] = m.get("confidence", 0.8)
                    det["matched_by"] = "cyclic_reflective_vlm"
                if det["bbox_id"] == m.get("name_id",-1) and det["class_id"] == 5:
                    matched_name_ids.add(det["bbox_id"])

        # æ ‡è®°ä½¿ç”¨çŠ¶æ€
        for det in detects:
            if det["class_id"] == 5:
                det["used_as_name"] = det["bbox_id"] in matched_name_ids

    def _is_converged(self, old: List[Dict], new: List[Dict]) -> bool:
        """åŸºäº compound_id â†” name_id æ˜ å°„çš„ Jaccard ç›¸ä¼¼åº¦åˆ¤æ–­æ”¶æ•›"""
        old_set = {(m['compound_id'], m.get("name_id",-1)) for m in old}
        new_set = {(m['compound_id'], m.get("name_id",-1)) for m in new}
        union = len(old_set | new_set)
        if union == 0:
            return True
        inter = len(old_set & new_set)
        return (inter / union) >= self.convergence_tol

    def _parse_json_list(self, text: str) -> List[Dict]:
        """å®‰å…¨è§£æ JSON åˆ—è¡¨"""
        try:
            cleaned = clean_json_response(text)
            result = json.loads(cleaned)
            return result if isinstance(result, list) else []
        except:
            return []

    def _extract_json_block(self, text: str) -> str:
        """ä»æ–‡æœ¬ä¸­æå– ```json ... ``` ä¸­çš„å†…å®¹"""
        start = text.find("```json") + 7
        end = text.find("```", start)
        if start > 6 and end > start:
            return text[start:end].strip()
        return clean_json_response(text)

    def _encode_image(self, image_path: str) -> str:
        """ç¼–ç å›¾åƒä¸º base64 URL"""
        ext = os.path.splitext(image_path)[1].lower()
        mime = {'png': 'image/png', 'jpg': 'image/jpeg', 'jpeg': 'image/jpeg'}.get(ext[1:], 'image/png')
        with open(image_path, "rb") as f:
            b64 = base64.b64encode(f.read()).decode('utf-8')
        return f"data:{mime};base64,{b64}"
